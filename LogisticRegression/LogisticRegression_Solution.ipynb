{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IRIS Dataset\n",
    "picture and text published from http://suruchifialoke.com/2016-10-13-machine-learning-tutorial-iris-classification/\n",
    "![title](iris.png)\n",
    "\n",
    "Three Iris varieties were used in the Iris flower data set outlined by Ronald Fisher in his famous 1936 paper “The use of multiple measurements in taxonomic problems as an example of linear discriminant analysis” PDF. Since then his paper has been cited over 2000 times and the data set has been used by almost every data science beginner.\n",
    "\n",
    "The data set consists of:\n",
    "\n",
    "150 samples\n",
    "3 labels: species of Iris (Iris setosa, Iris virginica and Iris versicolor)\n",
    "\n",
    "4 features: length and the width of the sepals and petals, in centimetres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "random_state = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sklearn libraray comes with IRIS data pre-loaded, which we would convert into a pandas dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_iris_dataset():\n",
    "    iris = datasets.load_iris()\n",
    "    iris_df = pd.DataFrame(iris.data, columns= iris.feature_names)\n",
    "    iris_df['target'] = iris.target\n",
    "    print('shape', iris_df.shape)\n",
    "    iris_df.head( )\n",
    "    return iris_df, iris.target_names\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Read data an print first five rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_df, target_names = get_iris_dataset()\n",
    "iris_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print data info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target field in data represents the  species of flower which are mapped as mapped as\n",
    "<br>setosa : 0, \n",
    "<br>versicolor: 1 \n",
    "<br>virginica: 2. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print Target Names\n",
    "print(target_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see  that there are 50  samples of each species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_df.target.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Data\n",
    "We will only sepal length as feature and check if we can predict the flower species based on sepal length only .\n",
    "We will only predict two classes of flowers \n",
    "\n",
    "setosa : 0\n",
    "<br>versicolor: 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# select the rows with 0 and 1 target values\n",
    "data = iris_df[iris_df.target.isin([0,1]) ]\n",
    "feature = 'sepal length (cm)'\n",
    "\n",
    "#y is the target value and X is feature column\n",
    "y   = data['target']\n",
    "X   = data[feature]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Data into  training and test set\n",
    "Split the data into training set and test set such that number of samples in training and test set are in 80:20 ratio. The model will be trained on training set and then evalauted on test set. We use stratified sampling so that the ratio of each class of flower is same in training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = random_state, stratify = y )\n",
    "\n",
    "X_train = X_train.values.reshape(-1,1)\n",
    "X_test = X_test.values.reshape(-1,1)\n",
    "\n",
    "\n",
    "print('Train Shape', X_train.shape, 'Test Shape', X_test.shape )\n",
    "y_train.value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Training Data\n",
    "Plot the sepal length and corresponding class of flower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_classes(X_train, y_train):\n",
    "    train_df = pd.DataFrame()\n",
    "    train_df[feature] = X_train.ravel()   \n",
    "    train_df['target'] = y_train.values\n",
    "    plt.figure(figsize = (10, 6))\n",
    "#     ax = sns.scatterplot(x= feature, y= 'target', hue=\"target\", \n",
    "#                        style ='target', palette=\"Set2\", data= train_df)\n",
    "    train_0 = train_df[train_df['target'] == 0]\n",
    "    train_1 = train_df[train_df['target'] == 1]\n",
    "    plt.xlabel(feature)\n",
    "    plt.ylabel('class')\n",
    "    plt.scatter(x =train_0[feature], y=  train_0['target'], label = 'setosa', color = 'r' )\n",
    "    plt.scatter(x =train_1[feature], y=  train_1['target'] , label ='versicolor', color = 'g')\n",
    "    plt.legend( )\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_classes(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Model \n",
    "Train the Logistic Regression model using traning set data.\n",
    "\n",
    "The model documentaion can be accessed using link \n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression(random_state= random_state, C = 1, solver = 'lbfgs')\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict on Training set\n",
    "The prediction are probabilities for positive class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob = model.predict_proba(X_train)[:,-1]\n",
    "y_prob[:5]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the featue vs probabilties for Training Data\n",
    "The blue line is probability threshold for classifying target as 0 or 1\n",
    "The data above blue line are predicted as class 1 and below the line are predicted as class 0. We can see that there are some points below blue lines(in green) which are predicted as 1 but actually belong to class 0 (False Negatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def display_prob(X, y, y_prob):\n",
    "    train_df = pd.DataFrame()\n",
    "    train_df[feature] = X.ravel()\n",
    "    train_df['pred'] = y_prob   \n",
    "    train_df['Actual Classes'] = y.values\n",
    "    plt.figure(figsize=(10,6))\n",
    "#     ax = sns.scatterplot(x= train_df[feature], y =  y_prob, hue=\"Actual Classes\", \n",
    "#                           palette=\"Set2\", data= train_df  )\n",
    "    train_0 = train_df[train_df['Actual Classes'] == 0]\n",
    "    train_1 = train_df[train_df['Actual Classes'] == 1]\n",
    "    plt.xlabel(feature)\n",
    "    plt.ylabel('Probabilty')\n",
    "    plt.scatter(x =train_0[feature], y=  train_0['pred'], label = '0_setosa', color = 'r' )\n",
    "    plt.scatter(x =train_1[feature], y=  train_1['pred'] , label ='1_versicolor', color = 'g')\n",
    "    plt.axhline(y = 0.5, color = 'b')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_prob(X_train, y_train, y_prob )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the featue vs probabilties for Test data\n",
    "Similarly for test data there are points in both classes 0 and 1 which are incorrectly predicted. Can you find those points?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob = model.predict_proba(X_test)[:,-1]\n",
    "display_prob(X_test, y_test, y_prob )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Classes\n",
    "The predict_proba in previous section method ouputs probabilities. Lets predict classes instead of probalities and check.\n",
    "accuracy scores.\n",
    "Even though our training accuracy is 0.92 the test accuarcy is low.  We can set petal length as feature which would have given accuracy of 1 on both training and test set\n",
    "\n",
    "From the confusion  matrix for Test set\n",
    "<br>Number of correct Predictions = TN + TP = 6 + 8 = 14\n",
    "<br>False Positives = 4\n",
    "<br>False Negatives = 2 \n",
    "<br>Accuracy = TN + TP /(TP + TN + FP + FN) = 14/20 = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "y_pred = model.predict(X_train)\n",
    "print('Training Accuracy', accuracy_score(y_train, y_pred))\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print('\\nTest Accuracy', accuracy_score(y_test, y_pred))\n",
    "print('Test set confusion matrix\\n', confusion_matrix(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
